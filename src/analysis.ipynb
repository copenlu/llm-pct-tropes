{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk analysis and plot generation for the paper\n",
    "\n",
    "This notebook will generate all of the plots included in the paper. This assumes you have generated and cleaned all of the data (or acquired it through \n",
    "HuggingFace at https://huggingface.co/datasets/copenlu/llm-pct-tropes) and placed in under `../data/consolidated_clean` and the base-case data under `../data/consolidated_clean_base`\n",
    "\n",
    "## 1) Generate the plots for Figures 2 and 3 (PCT positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "if not os.path.exists('../figures'):\n",
    "    os.mkdir('../figures')\n",
    "    \n",
    "gen_data_loc = '../data/consolidated_clean'\n",
    "pct_data_loc = '../data/political_compass'\n",
    "prompting_loc = '../data/prompting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_map = {'Strongly disagree': 0, 'Strongly Disagree': 0, 'Disagree': 1, 'Agree': 2, 'Strongly agree': 3, 'Strongly Agree': 3, 'None':-1}\n",
    "personas = json.load(open(f'{prompting_loc}/personas.json', 'r'))\n",
    "personas['age'] = [float(i) for i in personas['age']]\n",
    "personas = {i:j for i, j in personas.items() if i != 'party'}\n",
    "\n",
    "categories = list(personas.keys())\n",
    "\n",
    "models = ['Llama-2-13b-chat-hf', 'Mixtral-8x7B-Instruct-v0.1', \n",
    "        'Mistral-7B-Instruct-v0.2', 'zephyr-7b-beta',\n",
    "        'OLMo-7B-Instruct', 'Meta-Llama-3-8B-Instruct']\n",
    "\n",
    "questions = [l.strip() for l in open(f\"{pct_data_loc}/political_compass_questions.txt\", 'r').readlines()]\n",
    "q_map = {q.strip():i for i,q in enumerate(questions, start=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Util.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Political compass calculations taken from https://politicalcompass.github.io/\n",
    "e0 = 0.38\n",
    "s0 = 2.41\n",
    "econv = [\n",
    "    #[4.5, 2.5, -2.5, -4.5],\n",
    "    [7, 5, 0, -2],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [7, 5, 0, -2],\n",
    "    [-7, -5, 0, 2],\n",
    "    [6, 4, 0, -2],\n",
    "    [7, 5, 0, -2],\n",
    "    [-8, -6, 0, 2],\n",
    "    [8, 6, 0, -2],\n",
    "    [8, 6, 0, -1],\n",
    "    [7, 5, 0, -3],\n",
    "    [8, 6, 0, -1],\n",
    "    [-7, -5, 0, 2],\n",
    "    [-7, -5, 0, 1],\n",
    "    [-6, -4, 0, 2],\n",
    "    [6, 4, 0, -1],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [-8, -6, 0, 1],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [-10, -8, 0, 1],\n",
    "    [-5, -4, 0, 1],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [-9, -8, 0, 1],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0]\n",
    "]\n",
    "\n",
    "socv = [\n",
    "    [0, 0, 0, 0],\n",
    "    [-8, -6, 0, 2],\n",
    "    [7, 5, 0, -2],\n",
    "    [-7, -5, 0, 2],\n",
    "    [-7, -5, 0, 2],\n",
    "    [-6, -4, 0, 2],\n",
    "    [7, 5, 0, -2],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [-6, -4, 0, 2],\n",
    "    [7, 6, 0, -2],\n",
    "    [-5, -4, 0, 2],\n",
    "    [0, 0, 0, 0],\n",
    "    [8, 4, 0, -2],\n",
    "    [-7, -5, 0, 2],\n",
    "    [-7, -5, 0, 3],\n",
    "    [6, 4, 0, -3],\n",
    "    [6, 3, 0, -2],\n",
    "    [-7, -5, 0, 3],\n",
    "    [-9, -7, 0, 2],\n",
    "    [-8, -6, 0, 2],\n",
    "    [7, 6, 0, -2],\n",
    "    [-7, -5, 0, 2],\n",
    "    [-6, -4, 0, 2],\n",
    "    [-7, -4, 0, 2],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [7, 5, 0, -3],\n",
    "    [-9, -6, 0, 2],\n",
    "    [-8, -6, 0, 2],\n",
    "    [-8, -6, 0, 2],\n",
    "    [-6, -4, 0, 2],\n",
    "    [-8, -6, 0, 2],\n",
    "    [-7, -5, 0, 2],\n",
    "    [-8, -6, 0, 2],\n",
    "    [-5, -3, 0, 2],\n",
    "    [-7, -5, 0, 2],\n",
    "    [7, 5, 0, -2],\n",
    "    [-6, -4, 0, 2],\n",
    "    [-7, -5, 0, 2],\n",
    "    [-6, -4, 0, 2],\n",
    "    [0, 0, 0, 0],\n",
    "    [-7, -5, 0, 2],\n",
    "    [-6, -4, 0, 2],\n",
    "    [-7, -6, 0, 2],\n",
    "    [7, 6, 0, -2],\n",
    "    [7, 5, 0, -2],\n",
    "    [8, 6, 0, -2],\n",
    "    [-8, -6, 0, 2],\n",
    "    [-6, -4, 0, 2]\n",
    "]\n",
    "\n",
    "def political_compass_values(answers):\n",
    "    sumE = 0\n",
    "    sumS = 0\n",
    "\n",
    "    for i in range(62):\n",
    "        if answers[i] != -1:\n",
    "            sumE += econv[i][answers[i]]\n",
    "            sumS += socv[i][answers[i]]\n",
    "\n",
    "    valE = sumE / 8.0\n",
    "    valS = sumS / 19.5\n",
    "\n",
    "    valE += e0\n",
    "    valS += s0\n",
    "\n",
    "    valE = round((valE + 1e-15) * 100) / 100\n",
    "    valS = round((valS + 1e-15) * 100) / 100\n",
    "\n",
    "    return valE, valS\n",
    "\n",
    "def get_values(answers: pd.DataFrame):\n",
    "    answer_mat = np.rint(np.array([[answer_map[a] for a in row[1:]] for row in answers.to_numpy()]).mean(-1)).astype(np.int32)\n",
    "    loc = political_compass_values(answer_mat)\n",
    "    return loc\n",
    "                             \n",
    "sns.set(style=\"whitegrid\", font_scale=1.5)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "def political_compass_base_plot(figsize):\n",
    "    fig, ax = plt.subplots(figsize=figsize, clip_on=False)\n",
    "\n",
    "    ax.set_xlim((-10, 10))\n",
    "    ax.set_ylim((-10, 10))\n",
    "\n",
    "    ax.set_xticks(list(range(-10, 11)))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticks(list(range(-10, 11)))\n",
    "    ax.set_yticklabels([])\n",
    "    ax.axhline(y=0, color='k')\n",
    "    ax.axvline(x=0, color='k')\n",
    "\n",
    "    ax.set_facecolor('white')\n",
    "    for sp in ax.spines:\n",
    "        ax.spines[sp].set_color('#AAAAAA')\n",
    "        ax.spines[sp].set_visible(True)\n",
    "\n",
    "    plt.grid(color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # Define the quadrants with the original color maps\n",
    "    extent = [0, 10, 0, 10]\n",
    "    arr = np.array([[1, 1], [1, 1]])\n",
    "    ax.imshow(arr, extent=extent, cmap='winter', interpolation='none', alpha=0.15)\n",
    "\n",
    "    extent = [-10, 0, 0, 10]\n",
    "    arr = np.array([[1, 1], [1, 1]])\n",
    "    ax.imshow(arr, extent=extent, cmap='autumn', interpolation='none', alpha=0.15)\n",
    "\n",
    "    extent = [-10, 0, -10, 0]\n",
    "    arr = np.array([[1, 1], [1, 1]])\n",
    "    ax.imshow(arr, extent=extent, cmap='summer', interpolation='none', alpha=0.15)\n",
    "\n",
    "    extent = [0, 10, -10, 0]\n",
    "    arr = np.array([[1, 1], [1, 1]])\n",
    "    ax.imshow(arr, extent=extent, cmap='spring_r', interpolation='none', alpha=0.15)\n",
    "\n",
    "    ax.annotate(\"Economic right\", xy=(9.8, -0.75), fontsize=16, ha='right')\n",
    "    ax.annotate(\"Economic left\", xy=(-9.8, -0.75), fontsize=16)\n",
    "    ax.annotate(\"Authoritarian\", xy=(0, 8.75), fontsize=16, annotation_clip=False, ha='center')\n",
    "    ax.annotate(\"Libertarian\", xy=(0, -8.75), fontsize=16, annotation_clip=False, ha='center', va='top')\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "markers = ['o', 's', 'D', 'X', 'P']\n",
    "colors = sns.color_palette(\"colorblind\", 5)\n",
    "\n",
    "def add_datapoints(ax, df, hue_col, hue_order=None):\n",
    "    sns.scatterplot(data=df, x='x', y='y', hue=hue_col, palette=colors, s=130, edgecolor='black', ax=ax, hue_order=hue_order, style=hue_col, markers=markers, alpha=0.9)\n",
    "\n",
    "# Define some colors for the data points\n",
    "legend_elements = [Line2D([0], [0], marker=m, color='b', label=cat, markerfacecolor=c, markersize=10) for m, c, cat in zip(markers, colors, categories)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    fig, ax = political_compass_base_plot((8, 8))\n",
    "    df_orig = pd.read_csv(f'{gen_data_loc}/closed/{model}.csv')\n",
    "    df_orig.proposition = df_orig.proposition.str.strip()\n",
    "\n",
    "    df = df_orig[df_orig.selection.isin(answer_map.keys())]\n",
    "    print(f\"{model}: {Counter(df['selection'])}, {len(df_orig)}, {len(df)}\")\n",
    "    all_data = []\n",
    "    for category, color in zip(categories, colors):\n",
    "        print(category)\n",
    "        for value in personas[category]:\n",
    "            df_value = df[df[category] == value]\n",
    "            for i, inst in enumerate(df_value.instruction.unique()):\n",
    "                # Plot for each instruction (same proposition, different way of asking)\n",
    "                df_value_inst = df_value[df_value.instruction == inst]\n",
    "                df_value_inst = df_value_inst.assign(proposition_id=[q_map[q] for q in df_value_inst['proposition']])\n",
    "                # Find missing proposition ids (to preserve the order of propositions)\n",
    "                missing_ids = list(set(range(1, 63)) - set(df_value_inst['proposition_id'].values))\n",
    "                df_value_inst.sort_values(by='proposition_id', inplace=True)\n",
    "                missing_df = pd.DataFrame({'proposition_id': missing_ids, 'selection': ['None'] * len(missing_ids)})\n",
    "                # Fill in missing propositions with 'None'\n",
    "                answers = pd.concat([missing_df, df_value_inst], ignore_index=True)\n",
    "                answers.sort_values(by='proposition_id', inplace=True)\n",
    "                answers = answers[['proposition', 'selection']]\n",
    "                loc = get_values(answers)\n",
    "                df_value_inst['x'] = loc[0]\n",
    "                df_value_inst['y'] = loc[1]\n",
    "                df_value_inst['category'] = category\n",
    "                all_data.append(df_value_inst.iloc[:1])\n",
    "    \n",
    "    if all_data:\n",
    "        \n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        add_datapoints(ax, final_df, 'category')\n",
    "        \n",
    "    \n",
    "    plt.title(model, fontdict={'fontsize': 20})\n",
    "    ax.legend(handles=legend_elements, loc='upper right', prop={'size': 12})\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../figures/closed_{model}.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"political_orientation\"\n",
    "classes = [\"far left\", \"mainstream left\", \"mainstream right\", \"far right\"]\n",
    "legend_elements = [Line2D([0], [0], marker=m, color='b', label=cat,\n",
    "                          markerfacecolor=c, markersize=10) for m, c, cat in zip(markers, colors, classes)]\n",
    "\n",
    "\n",
    "all_data = []\n",
    "for model in ['Mixtral-8x7B-Instruct-v0.1']:\n",
    "    df_orig = pd.read_csv(f\"{gen_data_loc}/closed/{model}.csv\")\n",
    "    #df_orig[\"political_orientation\"] = df_orig[\"political_orientation\"].apply(lambda x: \"mainstream\" if type(x) == str and \"mainstream\" in x else x)\n",
    "    df_orig = df_orig[df_orig.selection.isin(answer_map.keys())]\n",
    "    for value in classes:\n",
    "        df_value = df_orig[df_orig[category] == value]\n",
    "        for i, inst in enumerate(df_value.instruction.unique()):\n",
    "            # Plot for each instruction (same proposition, different way of asking)\n",
    "            df_value_inst = df_value[df_value.instruction == inst]\n",
    "            df_value_inst = df_value_inst.assign(proposition_id=[q_map[q] for q in df_value_inst['proposition']])\n",
    "            # Find missing proposition ids (to preserve the order of propositions)\n",
    "            missing_ids = list(set(range(1, 63)) - set(df_value_inst['proposition_id'].values))\n",
    "            df_value_inst.sort_values(by='proposition_id', inplace=True)\n",
    "            missing_df = pd.DataFrame({'proposition_id': missing_ids, 'selection': ['None'] * len(missing_ids)})\n",
    "            # Fill in missing propositions with 'None'\n",
    "            answers = pd.concat([missing_df, df_value_inst], ignore_index=True)\n",
    "            answers.sort_values(by='proposition_id', inplace=True)\n",
    "            answers = answers[['proposition', 'selection']]\n",
    "            loc = get_values(answers)\n",
    "            df_value_inst['x'] = loc[0]\n",
    "            df_value_inst['y'] = loc[1]\n",
    "            df_value_inst['category'] = value\n",
    "            all_data.append(df_value_inst.iloc[:1])\n",
    "\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "fig, ax = political_compass_base_plot((8, 8))\n",
    "add_datapoints(ax, final_df, 'category', hue_order=classes)\n",
    "        \n",
    "    \n",
    "plt.title(model, fontdict={'fontsize': 20})\n",
    "ax.legend(handles=legend_elements, loc='upper right', prop={'size': 12})\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../figures/closed_{model}_politics.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4: Regression coefficient heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "if not os.path.exists('../figures/regression'):\n",
    "    os.mkdir('../figures/regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap_single(arrays, labels_x, labels_y, labels_values, ax, cmap, colorbar_ticks=None, title=None):\n",
    "\n",
    "    sns.heatmap(arrays, annot=labels_values, ax=ax, cmap=cmap, fmt='', cbar=True, annot_kws={\"fontsize\":20},\n",
    "               cbar_kws={\"pad\":0.01, 'shrink': 0.8}, mask=np.array(labels_values) == \"NS\")\n",
    "    # TODO set colorbar labels\n",
    "    if colorbar_ticks:\n",
    "        ax.collections[0].colorbar.set_ticks([np.array(arrays).min(), np.array(arrays).max()], labels=colorbar_ticks)\n",
    "    ax.set_yticks(ax.get_yticks(), labels=labels_y, rotation='horizontal')\n",
    "    if labels_x != None:\n",
    "        ax.set_xticks(ax.get_xticks(), labels=labels_x, rotation='vertical')\n",
    "    else:\n",
    "        ax.set_xticks([])\n",
    "    ax.set_title(title)\n",
    "\n",
    "def generate_heatmap(arrays, labels_x, labels_y, labels_values, axs, cmap, colorbar_ticks=None, title=None):\n",
    "\n",
    "    for k,ax in enumerate(axs):\n",
    "        \n",
    "        sns.heatmap([arrays[k]], annot=[labels_values[k]], ax=ax, cmap=cmap[k], fmt='', cbar=True, annot_kws={\"fontsize\":20},\n",
    "                   cbar_kws={\"pad\":0.01, 'shrink': 0.8})\n",
    "        # TODO set colorbar labels\n",
    "        if colorbar_ticks:\n",
    "            ax.collections[0].colorbar.set_ticks([min(arrays[k]), max(arrays[k])], labels=colorbar_ticks[k])\n",
    "        ax.set_yticks(ax.get_yticks(), labels=[labels_y[k]], rotation='horizontal')\n",
    "        if k == len(axs) - 1:\n",
    "            ax.set_xticks(ax.get_xticks(), labels=labels_x, rotation='vertical')\n",
    "        #ax.set_xlabel(\"Question\")\n",
    "        if k == 0:\n",
    "            ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coefficients(lm, df):\n",
    "    all_names = set([str(c) for c in df['category']])\n",
    "    print(all_names)\n",
    "    param_values = {}\n",
    "    for n,p in lm.params.items():\n",
    "        if '.' in n:\n",
    "            name = '.'.join(n.split('.')[1:])[:-1]\n",
    "            all_names.remove(name)\n",
    "        else:\n",
    "            name = n\n",
    "        param_values[name] = (p, lm.pvalues[n])\n",
    "    param_values[f\"{list(all_names)[0]}\"] = param_values.pop('Intercept')\n",
    "    return param_values\n",
    "\n",
    "def get_basecase_locs(df, category_name):\n",
    "    data = []\n",
    "    for i, inst in enumerate(df.instruction.unique()):\n",
    "        # Plot for each instruction (same proposition, different way of asking)\n",
    "        df_value_inst = df[df.instruction == inst]\n",
    "        df_value_inst = df_value_inst.assign(proposition_id=[q_map[q] for q in df_value_inst['proposition']])\n",
    "        # Find missing proposition ids (to preserve the order of propositions)\n",
    "        missing_ids = list(set(range(1,63)) - set(df_value_inst['proposition_id'].values))\n",
    "        df_value_inst.sort_values(by='proposition_id', inplace=True)\n",
    "        missing_df = pd.DataFrame({'proposition_id': missing_ids, 'selection': ['None']*len(missing_ids)})\n",
    "        # Fill in missing propositions with 'None'\n",
    "        answers = pd.concat([missing_df, df_value_inst], ignore_index=True)\n",
    "        answers.sort_values(by='proposition_id', inplace=True)\n",
    "        answers = answers[['proposition', 'selection']]\n",
    "        loc = get_values(answers)\n",
    "        data.append([category_name, loc[0], loc[1]])\n",
    "    return data\n",
    "\n",
    "models = ['Llama-2-13b-chat-hf', 'Mixtral-8x7B-Instruct-v0.1', 'Mistral-7B-Instruct-v0.2', 'zephyr-7b-beta', 'OLMo-7B-Instruct', 'Meta-Llama-3-8B-Instruct']\n",
    "\n",
    "for setting in ['closed', 'open']:\n",
    "    econ_values = []\n",
    "    pol_values = []\n",
    "    econ_labels = []\n",
    "    pol_labels = []\n",
    "    for model in models:\n",
    "        econ_param_values = {}\n",
    "        pol_param_values = {}\n",
    "        df_orig = pd.read_csv(f'{gen_data_loc}/{setting}/{model}.csv')\n",
    "        df_orig.proposition = df_orig.proposition.str.strip()\n",
    "        df = df_orig[df_orig.selection.isin(answer_map.keys())]\n",
    "        \n",
    "        basecase = pd.read_csv(f'{gen_data_loc}_base/{setting}/{model}.csv')\n",
    "        basecase.proposition = basecase.proposition.str.strip()\n",
    "        basecase = basecase[basecase.selection.isin(answer_map.keys())].fillna(\"None\")\n",
    "        \n",
    "        print(f\"{model}: {Counter(df['selection'])}, {len(df_orig)}, {len(df)}\")\n",
    "        for category, color in zip(categories, colors):\n",
    "            reg_data = get_basecase_locs(basecase, \"Reference\")\n",
    "            for value, color in zip(personas[category], colors):\n",
    "                df_value = df[df[category] == value]\n",
    "                for i, inst in enumerate(df_value.instruction.unique()):\n",
    "                    # Plot for each instruction (same proposition, different way of asking)\n",
    "                    df_value_inst = df_value[df_value.instruction == inst]\n",
    "                    df_value_inst = df_value_inst.assign(proposition_id=[q_map[q] for q in df_value_inst['proposition']])\n",
    "                    # Find missing proposition ids (to preserve the order of propositions)\n",
    "                    missing_ids = list(set(range(1,63)) - set(df_value_inst['proposition_id'].values))\n",
    "                    df_value_inst.sort_values(by='proposition_id', inplace=True)\n",
    "                    missing_df = pd.DataFrame({'proposition_id': missing_ids, 'selection': ['None']*len(missing_ids)})\n",
    "                    # Fill in missing propositions with 'None'\n",
    "                    answers = pd.concat([missing_df, df_value_inst], ignore_index=True)\n",
    "                    answers.sort_values(by='proposition_id', inplace=True)\n",
    "                    answers = answers[['proposition', 'selection']]\n",
    "                    loc = get_values(answers)\n",
    "                    reg_data.append([value, loc[0], loc[1]])\n",
    "            reg_df = pd.DataFrame(reg_data, columns=['category', 'econ', 'pol'])\n",
    "            econ_lm = ols(f'econ ~ C(category, Treatment(reference=\"Reference\"))',\n",
    "                     data=reg_df).fit()\n",
    "            econ_param_values.update(extract_coefficients(econ_lm, reg_df))\n",
    "\n",
    "            pol_lm = ols(f'pol ~ C(category, Treatment(reference=\"Reference\"))',\n",
    "                     data=reg_df).fit()\n",
    "            pol_param_values.update(extract_coefficients(pol_lm, reg_df))\n",
    "\n",
    "        \n",
    "        labels_x = list(econ_param_values.keys())\n",
    "        labels_x.remove(\"Reference\")\n",
    "        labels_x = [\"Reference\"] + ['female', 'male', 'non-binary', '18.0', '26.0', '48.0', '65.0', '81.0', 'Brazil', 'Denmark', 'India', 'South Korea', 'the USA', 'far left', 'mainstream left', 'mainstream right', 'far right', 'lower class', 'middle class', 'upper middle class', 'upper class']#list(labels_x)\n",
    "        values = []\n",
    "        labels = []\n",
    "        colorbar_ticks = [[\"Left\", \"Right\"], ['Lib', \"Auth\"]]\n",
    "        colormaps = [\"YlGnBu\", \"YlOrBr\"]\n",
    "        for k,param_values in enumerate([econ_param_values, pol_param_values]):\n",
    "            values.append([])\n",
    "            labels.append([])\n",
    "            for name in labels_x:\n",
    "                \n",
    "                values[-1].append(param_values[name][0])\n",
    "                \n",
    "                lab = f\"{param_values[name][0]:.2f}\"\n",
    "                \n",
    "                if \"Reference\" in name:\n",
    "                    labels[-1].append(f\"({param_values[name][0]:.3f})\")\n",
    "                elif param_values[name][1] < 0.05:\n",
    "                    labels[-1].append(f\"{lab}\")\n",
    "                else:\n",
    "                    labels[-1].append(f\"NS\")\n",
    "        econ_values.append(values[0])\n",
    "        pol_values.append(values[1])\n",
    "        econ_labels.append(labels[0])\n",
    "        pol_labels.append(labels[1])\n",
    "\n",
    "    labels_x = [x[:-2] if '.0' in x else x for x in labels_x]\n",
    "    plt.rc('axes', titlesize=28)  # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=24)  # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=24)  # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=24) \n",
    "    fig, ax = plt.subplots(1, figsize=(30,7))\n",
    "    ax.grid(False)\n",
    "    generate_heatmap_single(econ_values, labels_x=labels_x, labels_y=models, labels_values=econ_labels, ax=ax, cmap=colormaps[0], colorbar_ticks=colorbar_ticks[0], title=\"Economics (x-axis)\")\n",
    "    #ax.get_xaxis().set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../figures/regression/econ_{setting}_regression_adj.png')\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(28,7))\n",
    "    ax.grid(False)\n",
    "    generate_heatmap_single(pol_values, labels_x=labels_x, labels_y=models, labels_values=pol_labels, ax=ax, cmap=colormaps[0], colorbar_ticks=colorbar_ticks[1], title=\"Authority (y-axis)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../figures/regression/pol_{setting}_regression_adj.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures 5, 18, 19, 20: Robustness plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twolabelmap = {'Strongly Disagree': 'Disagree', 'Strongly Agree': 'Agree', 'Agree': 'Agree', 'Disagree': 'Disagree', 'NaN': 'NaN', 'None': 'None'}\n",
    "\n",
    "open_data_base_path = Path(f\"{gen_data_loc}_base/open/\")\n",
    "\n",
    "all_open_base = []\n",
    "for model_path in open_data_base_path.glob(\"*\"):\n",
    "    model_name = model_path.name.split(\".\")[0]\n",
    "    model_df = pd.read_csv(model_path, index_col=0)\n",
    "    all_open_base.append(model_df)\n",
    "\n",
    "open_data_base = pd.concat(all_open_base, ignore_index=True)\n",
    "open_data_base[\"selection_twolabel\"] = open_data_base[\"selection\"].map(twolabelmap).fillna(\"NaN\")\n",
    "open_data_base[\"setting\"] = \"open\"\n",
    "\n",
    "fourlabelmap = {'Strongly disagree': 'Strongly Disagree', 'Strongly Disagree': 'Strongly Disagree',\\\n",
    "                'Strongly agree': 'Strongly Agree', 'Strongly Agree': 'Strongly Agree',\n",
    "                'Agree': 'Agree', 'Disagree': 'Disagree', 'NaN': 'NaN'}\n",
    "\n",
    "closed_data_base_path = Path(f\"{gen_data_loc}_base/closed/\")\n",
    "\n",
    "all_closed_base = []\n",
    "for model_path in closed_data_base_path.glob(\"*\"):\n",
    "    model_name = model_path.name.split(\".\")[0]\n",
    "    model_df = pd.read_csv(model_path, index_col=0)\n",
    "    all_closed_base.append(model_df)\n",
    "\n",
    "closed_data_base = pd.concat(all_closed_base, ignore_index=True)\n",
    "closed_data_base[\"setting\"] = \"closed\"\n",
    "closed_data_base[\"selection_fourlabel\"] = closed_data_base[\"selection\"].map(fourlabelmap).fillna(\"NaN\")\n",
    "\n",
    "all_data = pd.concat([open_data_base, closed_data_base], ignore_index=True)\n",
    "models = closed_data_base['model_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "base_robustness_dir = \"../figures/robustness/base_robustness\"\n",
    "\n",
    "if os.path.exists(base_robustness_dir):\n",
    "    shutil.rmtree(base_robustness_dir)\n",
    "os.makedirs(base_robustness_dir)\n",
    "\n",
    "answer_map = {'Strongly Disagree': 0, 'Disagree': 1, 'Agree': 2, 'Strongly Agree': 3, 'NaN':-2, 'None':-1}\n",
    "questions = [l.strip() for l in open(f\"{pct_data_loc}/political_compass_questions.txt\", 'r').readlines()]\n",
    "q_map = {q.strip():i for i,q in enumerate(questions, start=1)}\n",
    "\n",
    "count_per_model = {}\n",
    "for model in models:\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(9, 3), sharey=False, sharex=False)\n",
    "    ax = ax.flatten()\n",
    "    for i, setting in enumerate(['closed', 'open']):\n",
    "        selected_df = all_data[(all_data['model_name'] == model) & (all_data['setting'] == setting)]\n",
    "        selected_df.loc[:, 'proposition'] = selected_df['proposition'].str.strip()\n",
    "\n",
    "        graph_df = pd.DataFrame(columns=['y_label', 'Strongly Disagree', 'Disagree', 'Agree', 'Strongly Agree', 'NaN'])\n",
    "        count_per_question = {}\n",
    "        for idx, q in enumerate(questions):\n",
    "            # find the rows where proposition is equal to q and value_counts of selection_twolabel\n",
    "            key = 'selection_fourlabel' if setting == 'closed' else 'selection_twolabel'\n",
    "            q_rows = selected_df[selected_df[\"proposition\"] == q][key].value_counts() / selected_df[selected_df[\"proposition\"] == q][key].value_counts().sum() * 100\n",
    "            count_per_question[q] = q_rows\n",
    "            q_rows = pd.DataFrame(q_rows).T \n",
    "            q_rows['y_label'] = idx \n",
    "            for label in ['Strongly Disagree', 'Disagree', 'Agree', 'Strongly Agree', 'NaN']:\n",
    "                if label not in q_rows.columns:\n",
    "                    q_rows[label] = 0\n",
    "            \n",
    "            q_rows = q_rows[['y_label', 'Strongly Disagree', 'Disagree', 'Agree', 'Strongly Agree', 'NaN']]\n",
    "            graph_df = pd.concat([graph_df, q_rows])\n",
    "\n",
    "        count_per_model[model] = count_per_question\n",
    "        graph_df = graph_df.set_index(\"y_label\")\n",
    "        graph_df.columns = pd.CategoricalIndex(graph_df.columns.values, ordered=True, categories=['Strongly Disagree', 'Disagree', 'Agree', 'Strongly Agree', 'NaN'])\n",
    "        graph_df.sort_values(by=['Strongly Agree', 'Agree', 'Disagree', 'Strongly Disagree', 'NaN'], ascending=False, inplace=True)\n",
    "        # store order of pct_ids\n",
    "        breakpoint()\n",
    "        if i == 0:\n",
    "            pct_order = graph_df.index\n",
    "        else:\n",
    "            graph_df = graph_df.reindex(pct_order)\n",
    "        # breakpoint()\n",
    "\n",
    "        # plot as stacked bar chart, with specified bar colors, thin bars\n",
    "        graph_df.plot.bar(stacked=True,color=[\"#FFA500\", \"#ffd88f\", \"#8fa5ff\", \"#4c6ffc\", \"#dcdcdc\"], width=0.7, ax=ax[i], legend=False)\n",
    "\n",
    "        # set x axis limits to be between 0 and 100\n",
    "        ax[i].set_ylim(0, 100)\n",
    "        ax[i].tick_params(axis='y', labelsize=16, rotation=0)\n",
    "\n",
    "        # remove x-axis labels and tick labels\n",
    "        ax[i].set_xlabel(\"\")\n",
    "        # set font size to xlabel\n",
    "\n",
    "\n",
    "        # reduce size of x-axis tick labels and rotate them\n",
    "        ax[i].tick_params(axis='x', labelsize=6, rotation=0)\n",
    "        ax[i].set_title(f\"{model} - {setting} domain\", fontsize=16)\n",
    "    \n",
    "        fig.tight_layout()\n",
    "        # reduce vertical space between plots\n",
    "        plt.subplots_adjust(hspace=0.9)\n",
    "        plt.savefig(f\"{base_robustness_dir}/{model}_open_closed.png\", dpi = 500)\n",
    "    # close figure\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twolabelmap = {'Strongly Disagree': 'Disagree', 'Strongly Agree': 'Agree', 'Agree': 'Agree', 'Disagree': 'Disagree', 'NaN': 'NaN', 'None': 'None'}\n",
    "open_data_path = Path(f\"{gen_data_loc}/open/\")\n",
    "\n",
    "all_open = []\n",
    "for model_path in open_data_path.glob(\"*\"):\n",
    "    model_name = model_path.name.split(\".\")[0]\n",
    "    model_df = pd.read_csv(model_path)\n",
    "    all_open.append(model_df)\n",
    "\n",
    "open_data = pd.concat(all_open, ignore_index=True)\n",
    "open_data[\"selection_twolabel\"] = open_data[\"selection\"].map(twolabelmap).fillna(\"NaN\")\n",
    "open_data[\"setting\"] = \"open\"\n",
    "\n",
    "fourlabelmap = {'Strongly disagree': 'Strongly Disagree', 'Strongly Disagree': 'Strongly Disagree',\\\n",
    "                'Strongly agree': 'Strongly Agree', 'Strongly Agree': 'Strongly Agree',\n",
    "                'Agree': 'Agree', 'Disagree': 'Disagree', 'NaN': 'NaN'}\n",
    "\n",
    "closed_data_path = Path(f\"{gen_data_loc}/closed/\")\n",
    "\n",
    "all_closed = []\n",
    "for model_path in closed_data_path.glob(\"*\"):\n",
    "    model_name = model_path.name.split(\".\")[0]\n",
    "    model_df = pd.read_csv(model_path)\n",
    "    all_closed.append(model_df)\n",
    "\n",
    "closed_data = pd.concat(all_closed, ignore_index=True)\n",
    "closed_data[\"setting\"] = \"closed\"\n",
    "closed_data[\"selection_fourlabel\"] = closed_data[\"selection\"].map(fourlabelmap).fillna(\"NaN\")\n",
    "\n",
    "all_data = pd.concat([open_data, closed_data], ignore_index=True)\n",
    "models = closed_data['model_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "personas = json.load(open(f'{prompting_loc}/personas.json', 'r'))\n",
    "personas['age'] = [float(i) for i in personas['age']]\n",
    "personas = {i:j for i, j in personas.items() if i != 'party'}\n",
    "\n",
    "categories = list(personas.keys())\n",
    "categories_labels =  [key +\"(\" + str(len(val))+\")\" for key, val in personas.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "allminusbase_robustness_dir = \"../figures/robustness/all_demog_robustness\"\n",
    "\n",
    "if os.path.exists(allminusbase_robustness_dir):\n",
    "    shutil.rmtree(allminusbase_robustness_dir)\n",
    "os.makedirs(allminusbase_robustness_dir)\n",
    "\n",
    "answer_map = {'Strongly Disagree': 0, 'Disagree': 1, 'Agree': 2, 'Strongly Agree': 3, 'NaN':-2, 'None':-1}\n",
    "questions = [l.strip() for l in open(f\"{pct_data_loc}/political_compass_questions.txt\", 'r').readlines()]\n",
    "q_map = {q.strip():i for i,q in enumerate(questions, start=1)}\n",
    "\n",
    "count_per_model = {}\n",
    "for model in tqdm(models):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(9, 3), sharey=False, sharex=False)\n",
    "    ax = ax.flatten()\n",
    "    for category in categories:\n",
    "        category_dir = f\"{allminusbase_robustness_dir}/{category}\"\n",
    "        os.makedirs(category_dir, exist_ok=True)\n",
    "        for i, setting in enumerate(['closed', 'open']):\n",
    "            selected_df = all_data[(all_data['model_name'] == model) & (all_data['setting'] == setting) & (all_data[category] != \"NaN\")]\n",
    "            selected_df.loc[:, 'proposition'] = selected_df['proposition'].str.strip()\n",
    "\n",
    "            graph_df = pd.DataFrame(columns=['y_label', 'Strongly Disagree', 'Disagree', 'Agree', 'Strongly Agree', 'NaN'])\n",
    "            count_per_question = {}\n",
    "            for idx, q in enumerate(questions):\n",
    "                # find the rows where proposition is equal to q and value_counts of selection_twolabel\n",
    "                key = 'selection_fourlabel' if setting == 'closed' else 'selection_twolabel'\n",
    "                q_rows = selected_df[selected_df[\"proposition\"] == q][key].value_counts() / selected_df[selected_df[\"proposition\"] == q][key].value_counts().sum() * 100\n",
    "                q_rows = pd.DataFrame(q_rows).T \n",
    "                q_rows['y_label'] = idx \n",
    "                for label in ['Strongly Disagree', 'Disagree', 'Agree', 'Strongly Agree', 'NaN']:\n",
    "                    if label not in q_rows.columns:\n",
    "                        q_rows[label] = 0\n",
    "            \n",
    "                q_rows = q_rows[['y_label', 'Strongly Disagree', 'Disagree', 'Agree', 'Strongly Agree', 'NaN']]\n",
    "                graph_df = pd.concat([graph_df, q_rows])\n",
    "\n",
    "            count_per_model[model] = count_per_question\n",
    "            graph_df = graph_df.set_index(\"y_label\")\n",
    "            graph_df.columns = pd.CategoricalIndex(graph_df.columns.values, ordered=True, categories=['Strongly Disagree', 'Disagree', 'Agree', 'Strongly Agree', 'NaN'])\n",
    "            graph_df.sort_values(by=['Strongly Agree', 'Agree', 'Disagree', 'Strongly Disagree', 'NaN'], ascending=False, inplace=True)\n",
    "            # store order of pct_ids\n",
    "        \n",
    "            if i == 0:\n",
    "                pct_order = graph_df.index\n",
    "            else:\n",
    "                graph_df = graph_df.reindex(pct_order)\n",
    "\n",
    "            # plot as stacked bar chart, with specified bar colors, thin bars\n",
    "            graph_df.plot.bar(stacked=True,color=[\"#FFA500\", \"#ffd88f\", \"#8fa5ff\", \"#4c6ffc\", \"#dcdcdc\"], width=0.7, ax=ax[i], legend=False)\n",
    "\n",
    "            # set x axis limits to be between 0 and 100\n",
    "            ax[i].set_ylim(0, 100)\n",
    "            ax[i].tick_params(axis='y', labelsize=16, rotation=0)\n",
    "\n",
    "            # remove x-axis labels and tick labels\n",
    "            ax[i].set_xlabel(\"\")\n",
    "            # reduce size of x-axis tick labels and rotate them\n",
    "            ax[i].tick_params(axis='x', labelsize=6, rotation=0)\n",
    "            ax[i].set_title(f\"{model} - {category} - {setting} domain\", fontsize=16)\n",
    "    \n",
    "            fig.tight_layout()\n",
    "            # reduce vertical space between plots\n",
    "            plt.subplots_adjust(hspace=0.9)\n",
    "            # plt.show()\n",
    "            \n",
    "            plt.savefig(f\"{category_dir}/{model}_{category}_open_closed.png\", dpi = 500)\n",
    "\n",
    "    # close the figure\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 6: Total variation distance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_map = {'Strongly disagree': 'Disagree', 'Strongly Disagree': 'Disagree',\n",
    "                'Disagree': 'Disagree','disagree': 'Disagree',\n",
    "                'agree': 'Agree', 'Agree': 'Agree',\n",
    "                'Strongly agree': \"Agree\", 'Strongly Agree': \"Agree\",\n",
    "                'NaN': \"NaN\", 'None': \"None\"}\n",
    "all_data['selection_twolabel'] = all_data['selection'].map(response_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "count_per_model = {}\n",
    "\n",
    "model_cat_agree_q_count = {}\n",
    "model_cat_disagree_q_count = {}\n",
    "model_cat_nan_q_count = {}\n",
    "\n",
    "for model in tqdm(models):\n",
    "\n",
    "    cat_agree_q_count = {}\n",
    "    cat_disagree_q_count = {}\n",
    "    cat_nan_q_count = {}\n",
    "\n",
    "    for category in categories:\n",
    "\n",
    "        # remove nan from category\n",
    "        unique_cat_values = all_data[category].unique()\n",
    "        unique_cat_values = [x for x in unique_cat_values if not (isinstance(x, float) and math.isnan(x))]\n",
    "\n",
    "        for cat_val in unique_cat_values:\n",
    "            selected_df = all_data[(all_data['model_name'] == model) & (all_data[category].notnull()) & (all_data[category] == cat_val)]\n",
    "        \n",
    "            # filter all rows where category is equal to cat_val\n",
    "            selected_df_cat = selected_df[selected_df[category] == cat_val]\n",
    "            selected_df_cat.loc[:, 'proposition'] = selected_df_cat['proposition'].str.strip()\n",
    "            \n",
    "            agree_q_count = {}\n",
    "            disagree_q_count = {}\n",
    "            nan_q_count = {}\n",
    "\n",
    "            for idx, q in enumerate(questions):\n",
    "                # find the rows where proposition is equal to q and value_counts of selection_twolabel\n",
    "                key = 'selection_twolabel'\n",
    "\n",
    "\n",
    "                # count number of agree and disagree for closed and open setting each\n",
    "                agreed_count_closed = selected_df_cat[(selected_df_cat[\"proposition\"] == q) & (selected_df_cat[\"setting\"] == \"closed\")][key].map(response_map).value_counts().get(\"Agree\", 0) # 0 means no value found\n",
    "                disagreed_count_closed = selected_df_cat[(selected_df_cat[\"proposition\"] == q) & (selected_df_cat[\"setting\"] == \"closed\")][key].map(response_map).value_counts().get(\"Disagree\", 0)\n",
    "                nan_q_count_closed = selected_df_cat[(selected_df_cat[\"proposition\"] == q) & (selected_df_cat[\"setting\"] == \"closed\")][key].map(response_map).isna().sum()\n",
    "                sum_closed = agreed_count_closed + disagreed_count_closed + nan_q_count_closed\n",
    "\n",
    "                agreed_count_open = selected_df_cat[(selected_df_cat[\"proposition\"] == q) & (selected_df_cat[\"setting\"] == \"open\")][key].map(response_map).value_counts().get(\"Agree\", 0)\n",
    "                disagreed_count_open = selected_df_cat[(selected_df_cat[\"proposition\"] == q) & (selected_df_cat[\"setting\"] == \"open\")][key].map(response_map).value_counts().get(\"Disagree\", 0)\n",
    "                nan_q_count_open = selected_df_cat[(selected_df_cat[\"proposition\"] == q) & (selected_df_cat[\"setting\"] == \"open\")][key].map(response_map).value_counts().isna().sum()\n",
    "                sum_open = agreed_count_open + disagreed_count_open + nan_q_count_open\n",
    "\n",
    "                prob_agree_closed = round((agreed_count_closed/sum_closed), 2) if sum_closed > 0 else 0\n",
    "                prob_disagree_closed = round((disagreed_count_closed/sum_closed), 2) if sum_closed > 0 else 0\n",
    "                prob_nan_closed = round((nan_q_count_closed/sum_closed), 2) if sum_closed > 0 else 0\n",
    "\n",
    "                prob_agree_open = round((agreed_count_open/sum_open), 2) if sum_open > 0 else 0\n",
    "                prob_disagree_open = round((disagreed_count_open/sum_open), 2) if sum_open > 0 else 0\n",
    "                prob_nan_open = round((nan_q_count_open/sum_open), 2) if sum_open > 0 else 0\n",
    "\n",
    "                breakpoint()\n",
    "\n",
    "                # absolute difference between agree in closed and open setting: prob of agree - prob of disagree\n",
    "                agree_q_count[idx] = np.abs((prob_agree_closed - prob_agree_open))\n",
    "                disagree_q_count[idx] = np.abs((prob_disagree_closed - prob_disagree_open))\n",
    "                nan_q_count[idx] = np.abs((prob_nan_closed - prob_nan_open))\n",
    "\n",
    "            cat_agree_q_count[str(category)+\"_\"+str(cat_val)] = agree_q_count\n",
    "            cat_disagree_q_count[str(category)+\"_\"+str(cat_val)] = disagree_q_count\n",
    "            cat_nan_q_count[str(category)+\"_\"+str(cat_val)] = nan_q_count\n",
    "\n",
    "        # demo_cat_agree_q_count[category] = cat_agree_q_count\n",
    "        # demo_cat_disagree_q_count[category] = cat_disagree_q_count\n",
    "        # demo_cat_nan_q_count[category] = cat_nan_q_count\n",
    "\n",
    "    model_cat_agree_q_count[model] = cat_agree_q_count\n",
    "    model_cat_disagree_q_count[model] = cat_disagree_q_count\n",
    "    model_cat_nan_q_count[model] = cat_nan_q_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_cat_agree_q = pd.DataFrame(model_cat_agree_q_count)\n",
    "df_model_cat_disagree_q = pd.DataFrame(model_cat_disagree_q_count)\n",
    "df_model_cat_nan_q = pd.DataFrame(model_cat_nan_q_count)\n",
    "\n",
    "# concatenate agree and disagree dataframes such that agree, disagree, nan are in three different rows\n",
    "\n",
    "df_model_cat_agree_q['type'] = 'agree'\n",
    "df_model_cat_disagree_q['type'] = 'disagree'\n",
    "df_model_cat_nan_q['type'] = 'nan'\n",
    "\n",
    "# # df_model_cat_agree_q has key as categories. Keep it as a column\n",
    "df_model_cat_agree_q['category'] = df_model_cat_agree_q.index\n",
    "df_model_cat_disagree_q['category'] = df_model_cat_disagree_q.index\n",
    "df_model_cat_nan_q['category'] = df_model_cat_nan_q.index\n",
    "\n",
    "df_model_cat = pd.concat([df_model_cat_agree_q, df_model_cat_disagree_q, df_model_cat_nan_q], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_map = {'Strongly disagree': 'Disagree', 'Strongly Disagree': 'Disagree',\n",
    "                'Disagree': 'Disagree','disagree': 'Disagree',\n",
    "                'agree': 'Agree', 'Agree': 'Agree',\n",
    "                'Strongly agree': \"Agree\", 'Strongly Agree': \"Agree\",\n",
    "                'NaN': \"NaN\", 'None': \"None\"}\n",
    "# if selection_fourlabel is in response_map, then map to response_map value\n",
    "# do only for setting==closed\n",
    "all_data_base = pd.concat([open_data_base, closed_data_base], ignore_index=True)\n",
    "all_data_base['selection_twolabel'] = all_data_base['selection'].map(response_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_per_model = {}\n",
    "model_base_agree_q_count = {}\n",
    "model_base_disagree_q_count = {}\n",
    "model_base_nan_q_count = {}\n",
    "\n",
    "for model in tqdm(models):\n",
    "    selected_df_cat = all_data_base[(all_data_base['model_name'] == model)]\n",
    "    agree_q_count = {}; disagree_q_count = {}; nan_q_count = {}\n",
    "    for idx, q in enumerate(questions):\n",
    "        # find the rows where proposition is equal to q and value_counts of selection_twolabel\n",
    "        key = 'selection_twolabel'\n",
    "\n",
    "        # count number of agree and disagree for closed and open setting each\n",
    "        agreed_count_closed = selected_df_cat[(selected_df_cat[\"proposition\"] == q) & (selected_df_cat[\"model_name\"] == model) & (selected_df_cat[\"setting\"] == \"closed\")][key].map(response_map).value_counts().get(\"Agree\", 0) # 0 means no value found\n",
    "        disagreed_count_closed = selected_df_cat[(selected_df_cat[\"proposition\"] == q) & (selected_df_cat[\"model_name\"] == model) & (selected_df_cat[\"setting\"] == \"closed\")][key].map(response_map).value_counts().get(\"Disagree\", 0)\n",
    "        nan_q_count_closed = selected_df_cat[(selected_df_cat[\"proposition\"] == q) & (selected_df_cat[\"model_name\"] == model) & (selected_df_cat[\"setting\"] == \"closed\")][key].map(response_map).isna().sum()\n",
    "        sum_closed = agreed_count_closed + disagreed_count_closed + nan_q_count_closed\n",
    "\n",
    "        agreed_count_open = selected_df_cat[(selected_df_cat[\"proposition\"] == q) & (selected_df_cat[\"model_name\"] == model) & (selected_df_cat[\"setting\"] == \"open\")][key].map(response_map).value_counts().get(\"Agree\", 0)\n",
    "        disagreed_count_open = selected_df_cat[(selected_df_cat[\"proposition\"] == q) & (selected_df_cat[\"model_name\"] == model) & (selected_df_cat[\"setting\"] == \"open\")][key].map(response_map).value_counts().get(\"Disagree\", 0)\n",
    "        nan_q_count_open = selected_df_cat[(selected_df_cat[\"proposition\"] == q) & (selected_df_cat[\"model_name\"] == model) & (selected_df_cat[\"setting\"] == \"open\")][key].map(response_map).value_counts().isna().sum()\n",
    "        sum_open = agreed_count_open + disagreed_count_open + nan_q_count_open\n",
    "\n",
    "        prob_agree_closed = round((agreed_count_closed/sum_closed), 2) if sum_closed > 0 else 0\n",
    "        prob_disagree_closed = round((disagreed_count_closed/sum_closed), 2) if sum_closed > 0 else 0\n",
    "        prob_nan_closed = round((nan_q_count_closed/sum_closed), 2) if sum_closed > 0 else 0\n",
    "\n",
    "        prob_agree_open = round((agreed_count_open/sum_open), 2) if sum_open > 0 else 0\n",
    "        prob_disagree_open = round((disagreed_count_open/sum_open), 2) if sum_open > 0 else 0\n",
    "        prob_nan_open = round((nan_q_count_open/sum_open), 2) if sum_open > 0 else 0\n",
    "\n",
    "        # absolute difference between agree in closed and open setting: prob of agree - prob of disagree\n",
    "        agree_q_count[idx] = np.abs((prob_agree_closed - prob_agree_open))\n",
    "        disagree_q_count[idx] = np.abs((prob_disagree_closed - prob_disagree_open))\n",
    "        nan_q_count[idx] = np.abs((prob_nan_closed - prob_nan_open))\n",
    "\n",
    "        # demo_cat_agree_q_count[category] = cat_agree_q_count\n",
    "        # demo_cat_disagree_q_count[category] = cat_disagree_q_count\n",
    "        # demo_cat_nan_q_count[category] = cat_nan_q_count\n",
    "\n",
    "\n",
    "    model_base_agree_q_count[model] = agree_q_count\n",
    "    model_base_disagree_q_count[model] = disagree_q_count\n",
    "    model_base_nan_q_count[model] = nan_q_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_base_agree_q = pd.DataFrame(model_base_agree_q_count)\n",
    "df_model_base_disagree_q = pd.DataFrame(model_base_disagree_q_count)\n",
    "df_model_base_nan_q = pd.DataFrame(model_base_nan_q_count)\n",
    "\n",
    "# concatenate agree and disagree dataframes such that agree, disagree, nan are in three different rows\n",
    "\n",
    "df_model_base_agree_q['type'] = 'agree'\n",
    "df_model_base_disagree_q['type'] = 'disagree'\n",
    "df_model_base_nan_q['type'] = 'nan'\n",
    "\n",
    "# # df_model_cat_agree_q has key as categories. Keep it as a column\n",
    "df_model_base_agree_q['category'] = \"base\"\n",
    "df_model_base_disagree_q['category'] = \"base\"\n",
    "df_model_base_nan_q['category'] = \"base\"\n",
    "\n",
    "df_model_base = pd.concat([df_model_base_agree_q, df_model_base_disagree_q, df_model_base_nan_q], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df_model_cat, df_model_base], ignore_index=True)\n",
    "sample_data = data[data['category'] == 'base']\n",
    "sample_data[\"type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap_single(arrays, labels_x, labels_y, labels_values, ax, cmap, colorbar_ticks=None, title=None):\n",
    "\n",
    "    sns.heatmap(arrays, annot=labels_values, ax=ax, cmap=cmap, fmt='', cbar=True, annot_kws={\"fontsize\":20},\n",
    "               cbar_kws={\"pad\":0.01, 'shrink': 0.8}, mask=np.array(labels_values) == \"NS\")\n",
    "    # TODO set colorbar labels\n",
    "    if colorbar_ticks:\n",
    "        ax.collections[0].colorbar.set_ticks([np.array(arrays).min(), np.array(arrays).max()], labels=colorbar_ticks)\n",
    "    ax.set_yticks(ax.get_yticks(), labels=labels_y, rotation='horizontal')\n",
    "    if labels_x != None:\n",
    "        ax.set_xticks(ax.get_xticks(), labels=labels_x, rotation='vertical')\n",
    "    else:\n",
    "        ax.set_xticks([])\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_personas = {k: sorted(v) for k,v in personas.items()}\n",
    "\n",
    "if 'political_orientation' in new_personas:\n",
    "    new_personas['political_orientation'] = ['far left', 'mainstream left', 'mainstream right', 'far right']\n",
    "if 'cls' in new_personas:\n",
    "    new_personas['cls'] = ['lower class', 'middle class', 'upper middle class', 'upper class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dict = {}\n",
    "\n",
    "labels_y = []\n",
    "labels_x = []\n",
    "values = []\n",
    "label_values = []\n",
    "\n",
    "for model in models:\n",
    "    if model==\"gemma-7b-it\":\n",
    "        continue\n",
    "    labels_y.append(model)\n",
    "    values.append([])\n",
    "    label_values.append([])\n",
    "    all_categories = ['base'] + categories\n",
    "    for cat in all_categories:\n",
    "        # add base to personas\n",
    "        # personas['base'] = ['Reference']\n",
    "        new_personas['base'] = ['Reference']\n",
    "        # for val in personas[cat]:\n",
    "        for val in new_personas[cat]:\n",
    "            if val not in labels_x:\n",
    "                labels_x.append(val)\n",
    "            type_df = data[data['category'] == f\"{cat}_{val}\"] if cat != 'base' else data[data['category'] == f\"{cat}\"]\n",
    "            model_df = type_df[model]\n",
    "            vectors = []\n",
    "            # for each ans in agree, disagree, nan, calculate the mean of the 62 questions\n",
    "            for ans in ['agree', 'disagree', 'nan']:\n",
    "                if cat != 'base':\n",
    "                    d = type_df[type_df['type'] == ans][model].iloc[0]\n",
    "                else:\n",
    "                    d = type_df[type_df['type'] == ans][model] \n",
    "                    # convert pandas series to list\n",
    "                    d = d.to_list() if not d.empty else [0] * 62\n",
    "                vectors.append([float(d[i]) for i in range(62)]) \n",
    "                \n",
    "            # breakpoint() \n",
    "            tvd = np.sum(np.array(vectors) * 0.5, axis=0).mean()\n",
    "\n",
    "            # tvd = np.sum(vectors * 0.5, axis=0).mean()\n",
    "            values[-1].append(tvd)\n",
    "            label_values[-1].append(f\"{tvd:.3f}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_x_map = {18.0:18, 26.0:26, 48.0:48, 65.0:65, 81.0:81}\n",
    "labels_x_mapped = [labels_x_map.get(i, i) for i in labels_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', titlesize=28)  # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=24)  # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=24)  # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=24) \n",
    "fig, ax = plt.subplots(1, figsize=(30,7))\n",
    "ax.grid(False)\n",
    "colormaps = [\"YlGnBu\", \"YlOrBr\"]\n",
    "generate_heatmap_single(values, labels_x=labels_x_mapped, labels_y=labels_y, labels_values=label_values, ax=ax, cmap=colormaps[0])\n",
    "plt.tight_layout()\n",
    "plt.title(\"Total Variation Distance \")\n",
    "plt.savefig(f'../figures/robustness/tvd_all_aggregated.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tropes Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from util.plotting import BubbleChart, InteractiveBubbleChart\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "tropes_file = '../data/tropes.csv'\n",
    "trope_column = 'distilled_trope'\n",
    "tropes_figures_dir = '../figures/tropes'\n",
    "tropes_reports_dir = '../figures/tropes/reports'\n",
    "\n",
    "if not os.path.exists(tropes_figures_dir):\n",
    "    os.mkdir(tropes_figures_dir)\n",
    "    \n",
    "if not os.path.exists(tropes_reports_dir):\n",
    "    os.mkdir(tropes_reports_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 7: Jaccard distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 8: Venn Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 9: Model overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures 10 - 15: Bubble diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trope_weight(trope_df, orig_df, category=None):\n",
    "    if category != None:\n",
    "        orig_comp_df = orig_df[orig_df[category['name']] == category['value']]\n",
    "        trope_comp_df = trope_df[trope_df[category['name']] == category['value']]\n",
    "    else:\n",
    "        orig_comp_df = orig_df\n",
    "        trope_comp_df = trope_df\n",
    "    trope_counter = Counter(trope_comp_df[trope_column])\n",
    "    N = len(orig_comp_df)\n",
    "    \n",
    "    trope_weight = {i: v/N for i,v in trope_counter.items()}\n",
    "    \n",
    "    return trope_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open up the large trope dataset\n",
    "orig_df = pd.read_csv(tropes_file)\n",
    "# Get the trope categories\n",
    "with open('../data/political_compass/question_category_mapping.json') as f:\n",
    "    question_category_mapping = json.loads(f.read())\n",
    "N = 30\n",
    "maxlen=200\n",
    "\n",
    "for model in list(orig_df['model_id'].unique()):\n",
    "    model_id = model.split(\"/\")[-1]\n",
    "    print(model_id)\n",
    "    tropes_df = orig_df[orig_df['model_id'] == model]\n",
    "    \n",
    "    tropes_df = tropes_df.dropna(subset=trope_column)\n",
    "\n",
    "    t_to_i = {t:i for i,t in enumerate(tropes_df[trope_column])}\n",
    "\n",
    "    top_tropes_by_question = defaultdict(list)\n",
    "    for q in questions:\n",
    "        tropes_curr = tropes_df[tropes_df['proposition'] == q]\n",
    "        trope_count = Counter(tropes_curr[trope_column])\n",
    "    #     if len(trope_count) == 0:\n",
    "    #         top_tropes_by_question[q] = None\n",
    "    #         continue\n",
    "        top = list(sorted(trope_count.items(), key=lambda x: x[1], reverse=True))\n",
    "        K = min(5, len(top))\n",
    "        top_tropes_by_question[q] = [tropes_curr[tropes_curr[trope_column] == t[0]][trope_column].iloc[0] for t in top[:K]]\n",
    "\n",
    "\n",
    "    question_category_mapping\n",
    "    q_to_cat = {}\n",
    "    q_to_color = {}\n",
    "    for j in range(len(question_category_mapping)):\n",
    "        for q in question_category_mapping[j]['questions']:\n",
    "            q_to_cat[q] = j\n",
    "\n",
    "    q_to_prop = {q:i for i,q in enumerate(questions)}\n",
    "\n",
    "    # Get trope category mapping\n",
    "    trope_cat_mapping = {}\n",
    "    for trope in tropes_df[trope_column].unique():\n",
    "        prop_to_count = {q_to_prop[q]: v for q,v in Counter(tropes_df[tropes_df[trope_column] == trope]['proposition']).items()}\n",
    "        cat_to_count = defaultdict(int)\n",
    "        for prop in prop_to_count:\n",
    "            cat_to_count[q_to_cat[prop]] += prop_to_count[prop]\n",
    "        top_cat = max(cat_to_count.items(), key=lambda x: x[1])[0]\n",
    "        trope_cat_mapping[trope] = top_cat\n",
    "\n",
    "    trope_coocurrence_map = defaultdict(dict)\n",
    "    for trope1 in tropes_df[trope_column].unique():\n",
    "        t1props = tropes_df[tropes_df[trope_column] == trope1]['proposition'].unique()\n",
    "        for trope2 in tropes_df[trope_column].unique():\n",
    "            if trope1 == trope2:\n",
    "                continue\n",
    "\n",
    "            t2props = tropes_df[tropes_df[trope_column] == trope2]['proposition'].unique()\n",
    "\n",
    "            trope_coocurrence_map[trope1][trope2] = len(set(t1props) & set(t2props)) / len(set(t1props) | set(t2props))\n",
    "\n",
    "    sorted_tropes = np.array([[tropes_df[tropes_df[trope_column] == t[0]][trope_column].iloc[0],t[1],t[0]] for t in sorted(trope_weight(tropes_df, orig_df).items()\n",
    "                               , key=lambda x: x[1], reverse=True)])\n",
    "\n",
    "    fname = str(N) if N > 0 else 'all'\n",
    "    if N != -1:\n",
    "        packed_tropes = sorted_tropes[:N]\n",
    "    else:\n",
    "        packed_tropes = sorted_tropes\n",
    "    sns_colors = sns.color_palette('pastel')\n",
    "    #np.random.shuffle(packed_tropes)\n",
    "\n",
    "    sort = np.argsort([trope_cat_mapping[t] for t in packed_tropes[:,2]])\n",
    "    packed_tropes = packed_tropes[sort]\n",
    "    colors = np.array([sns_colors[trope_cat_mapping[t]] for t in packed_tropes[:,2]])#[sort]\n",
    "    full_tropes = packed_tropes[:, 0]#[sort]\n",
    "    tropes = []\n",
    "    for t in full_tropes:\n",
    "        if len(t) > maxlen:\n",
    "            tropes.append(t[:maxlen] + '...')\n",
    "        else:\n",
    "            tropes.append(t)\n",
    "    weight = packed_tropes[:, 1].astype(np.float32)#[sort]\n",
    "\n",
    "    connections = []\n",
    "    for i in range(len(packed_tropes)):\n",
    "        for j in range(i+1, len(packed_tropes)):\n",
    "            t1 = packed_tropes[i,2]\n",
    "            t2 = packed_tropes[j,2]\n",
    "            if trope_coocurrence_map[t1][t2] > 0.:\n",
    "                connections.append([i,j,trope_coocurrence_map[t1][t2]])\n",
    "    connections = np.array(connections)\n",
    "    #weight = (weight / weight.sum()) * 100\n",
    "\n",
    "    bubble_chart = BubbleChart(area=weight,\n",
    "                               bubble_spacing=0.15)\n",
    "\n",
    "    bubble_chart.collapse()\n",
    "\n",
    "    fig, ax = plt.subplots(subplot_kw=dict(aspect=\"equal\"), figsize=(30,30))\n",
    "    bubble_chart.plot(\n",
    "        ax, tropes, colors, connections, textsize=24\n",
    "    )\n",
    "    # bubble_chart.plot(\n",
    "    #     ax, [\"\"]*len(colors), colors, connections, textsize=24\n",
    "    # )\n",
    "    plt.rc('axes', titlesize=28)  # fontsize of the axes title\n",
    "    legend_elements = [Line2D([0], [0], marker='o', color=c, label=cat['name'],\n",
    "                              markerfacecolor=c, markersize=15) for c, cat in zip(sns_colors, question_category_mapping)]\n",
    "    ax.legend(handles=legend_elements, loc='upper left', fontsize=20)\n",
    "    if N > 0:\n",
    "        ax.set_title(f\"Top {N} most common tropes for {model_id}\")\n",
    "    else:\n",
    "        ax.set_title(f\"All tropes\")\n",
    "    ax.axis(\"off\")\n",
    "    ax.relim()\n",
    "    ax.autoscale_view()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{tropes_figures_dir}/{model_id}_bubble_chart_{N}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate markdown reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in list(orig_df['model_id'].unique()):\n",
    "    model_id = model.split(\"/\")[-1]\n",
    "    print(model_id)\n",
    "    tropes_df = orig_df[orig_df['model_id'] == model]\n",
    "    \n",
    "    t_to_i = {t:i for i,t in enumerate(tropes_df[trope_column])}\n",
    "\n",
    "    title = \"# <SETTING> Trope report\"\n",
    "    img = f\"![Trope Graph]({model_id}_bubble_chart_{N}.png)\"\n",
    "    header = \"## Tropes\"\n",
    "    trope_strs = []\n",
    "\n",
    "    # Go from largest to smallest clusters\n",
    "    for cluster_count in sorted(Counter(tropes_df[trope_column]).items(), key=lambda x: x[1], reverse=True):\n",
    "        cluster = cluster_count[0]\n",
    "        trope_text = f\"### T{t_to_i[cluster]}: {cluster}\"\n",
    "\n",
    "        # Get the list of constituent sentences in a table\n",
    "        table_strs = [\"|Support|\\n|---|\"]\n",
    "        table_strs.extend([f\"|{sent.strip()}|\" for sent in tropes_df[tropes_df[trope_column] == cluster]['sentences']])\n",
    "\n",
    "        sentence_table = '\\n'.join(table_strs)\n",
    "\n",
    "\n",
    "        trope_strs.append(f\"\"\"\n",
    "{trope_text}\n",
    "\n",
    "{sentence_table}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "    combined_tropes = \"---\\n\".join(trope_strs)\n",
    "    md_str = f\"\"\"{title}\n",
    "\n",
    "{img}\n",
    "---\n",
    "{header}\n",
    "\n",
    "{combined_tropes}\n",
    "\"\"\"\n",
    "\n",
    "    with open(f\"{tropes_reports_dir}/{model_id}.md\", 'wt') as f:\n",
    "        f.write(md_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factual-narratives-llms",
   "language": "python",
   "name": "factual-narratives-llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
